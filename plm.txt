Gradient is computed non stochastically
Will train for 1 epochs with a batch size of 64
Computing on cpu
Using MNIST model
Initial model: Net(
  (conv1): Conv2d(1, 20, kernel_size=(5, 5), stride=(1, 1))
  (conv2): Conv2d(20, 50, kernel_size=(5, 5), stride=(1, 1))
  (fc1): Linear(in_features=800, out_features=500, bias=True)
  (fc2): Linear(in_features=500, out_features=10, bias=True)
)
A3RMS (
Parameter Group 0
    alpha: 0.99
    eps: 1e-08
    k: 5
    lr: 1e-05
)

Number of closure calls: 1

Train Epoch: 1 [0/60000 (0%)]	Loss: 2.312924
Train Epoch: 1 [640/60000 (1%)]	Loss: 2.316961
Train Epoch: 1 [1280/60000 (2%)]	Loss: 2.318334
Train Epoch: 1 [1920/60000 (3%)]	Loss: 2.308810
Train Epoch: 1 [2560/60000 (4%)]	Loss: 2.308557
Train Epoch: 1 [3200/60000 (5%)]	Loss: 2.312365
Train Epoch: 1 [3840/60000 (6%)]	Loss: 2.311935
Train Epoch: 1 [4480/60000 (7%)]	Loss: 2.298486
Train Epoch: 1 [5120/60000 (9%)]	Loss: 2.298021
Train Epoch: 1 [5760/60000 (10%)]	Loss: 2.276636
Train Epoch: 1 [6400/60000 (11%)]	Loss: 2.302107
Train Epoch: 1 [7040/60000 (12%)]	Loss: 2.269068
Train Epoch: 1 [7680/60000 (13%)]	Loss: 2.326907
Train Epoch: 1 [8320/60000 (14%)]	Loss: 2.297522
Train Epoch: 1 [8960/60000 (15%)]	Loss: 2.298174
Train Epoch: 1 [9600/60000 (16%)]	Loss: 2.303519
Train Epoch: 1 [10240/60000 (17%)]	Loss: 2.301148
Train Epoch: 1 [10880/60000 (18%)]	Loss: 2.328202
Train Epoch: 1 [11520/60000 (19%)]	Loss: 2.304039
Train Epoch: 1 [12160/60000 (20%)]	Loss: 2.316040
Train Epoch: 1 [12800/60000 (21%)]	Loss: 2.300956
Train Epoch: 1 [13440/60000 (22%)]	Loss: 2.320301
Train Epoch: 1 [14080/60000 (23%)]	Loss: 2.310820
Train Epoch: 1 [14720/60000 (25%)]	Loss: 2.316255
Train Epoch: 1 [15360/60000 (26%)]	Loss: 2.311892
Train Epoch: 1 [16000/60000 (27%)]	Loss: 2.307270
Train Epoch: 1 [16640/60000 (28%)]	Loss: 2.311492
Train Epoch: 1 [17280/60000 (29%)]	Loss: 2.317920
Train Epoch: 1 [17920/60000 (30%)]	Loss: 2.317337
Train Epoch: 1 [18560/60000 (31%)]	Loss: 2.306076
Train Epoch: 1 [19200/60000 (32%)]	Loss: 2.285508
Train Epoch: 1 [19840/60000 (33%)]	Loss: 2.324414
Train Epoch: 1 [20480/60000 (34%)]	Loss: 2.283285
Train Epoch: 1 [21120/60000 (35%)]	Loss: 2.315861
Train Epoch: 1 [21760/60000 (36%)]	Loss: 2.341650
Train Epoch: 1 [22400/60000 (37%)]	Loss: 2.310874
Train Epoch: 1 [23040/60000 (38%)]	Loss: 2.322984
Train Epoch: 1 [23680/60000 (39%)]	Loss: 2.306071
Train Epoch: 1 [24320/60000 (41%)]	Loss: 2.322724
Train Epoch: 1 [24960/60000 (42%)]	Loss: 2.309828
Train Epoch: 1 [25600/60000 (43%)]	Loss: 2.293470
Train Epoch: 1 [26240/60000 (44%)]	Loss: 2.330743
Train Epoch: 1 [26880/60000 (45%)]	Loss: 2.312875
Train Epoch: 1 [27520/60000 (46%)]	Loss: 2.249677
Train Epoch: 1 [28160/60000 (47%)]	Loss: 2.334522
Train Epoch: 1 [28800/60000 (48%)]	Loss: 2.307233
Train Epoch: 1 [29440/60000 (49%)]	Loss: 2.300983
Train Epoch: 1 [30080/60000 (50%)]	Loss: 2.320085
Train Epoch: 1 [30720/60000 (51%)]	Loss: 2.288237
Train Epoch: 1 [31360/60000 (52%)]	Loss: 2.321854
Train Epoch: 1 [32000/60000 (53%)]	Loss: 2.319666
Train Epoch: 1 [32640/60000 (54%)]	Loss: 2.299816
Train Epoch: 1 [33280/60000 (55%)]	Loss: 2.314366
Train Epoch: 1 [33920/60000 (57%)]	Loss: 2.309051
Train Epoch: 1 [34560/60000 (58%)]	Loss: 2.310118
Train Epoch: 1 [35200/60000 (59%)]	Loss: 2.302745
Train Epoch: 1 [35840/60000 (60%)]	Loss: 2.328180
Train Epoch: 1 [36480/60000 (61%)]	Loss: 2.334414
Train Epoch: 1 [37120/60000 (62%)]	Loss: 2.295090
Train Epoch: 1 [37760/60000 (63%)]	Loss: 2.302977
Train Epoch: 1 [38400/60000 (64%)]	Loss: 2.314580
Train Epoch: 1 [39040/60000 (65%)]	Loss: 2.317383
Train Epoch: 1 [39680/60000 (66%)]	Loss: 2.331951
Train Epoch: 1 [40320/60000 (67%)]	Loss: 2.324474
Train Epoch: 1 [40960/60000 (68%)]	Loss: 2.314668
Train Epoch: 1 [41600/60000 (69%)]	Loss: 2.307820
Train Epoch: 1 [42240/60000 (70%)]	Loss: 2.318013
Train Epoch: 1 [42880/60000 (71%)]	Loss: 2.312159
Train Epoch: 1 [43520/60000 (72%)]	Loss: 2.345287
Train Epoch: 1 [44160/60000 (74%)]	Loss: 2.287940
Train Epoch: 1 [44800/60000 (75%)]	Loss: 2.324338
Train Epoch: 1 [45440/60000 (76%)]	Loss: 2.300591
Train Epoch: 1 [46080/60000 (77%)]	Loss: 2.310734
Train Epoch: 1 [46720/60000 (78%)]	Loss: 2.285168
Train Epoch: 1 [47360/60000 (79%)]	Loss: 2.298987
Train Epoch: 1 [48000/60000 (80%)]	Loss: 2.326591
Train Epoch: 1 [48640/60000 (81%)]	Loss: 2.301277
Train Epoch: 1 [49280/60000 (82%)]	Loss: 2.313409
Train Epoch: 1 [49920/60000 (83%)]	Loss: 2.280298
Train Epoch: 1 [50560/60000 (84%)]	Loss: 2.287886
Train Epoch: 1 [51200/60000 (85%)]	Loss: 2.295540
Train Epoch: 1 [51840/60000 (86%)]	Loss: 2.297283
Train Epoch: 1 [52480/60000 (87%)]	Loss: 2.316032
Train Epoch: 1 [53120/60000 (88%)]	Loss: 2.305907
Train Epoch: 1 [53760/60000 (90%)]	Loss: 2.335155
Train Epoch: 1 [54400/60000 (91%)]	Loss: 2.307404
Train Epoch: 1 [55040/60000 (92%)]	Loss: 2.303416
Train Epoch: 1 [55680/60000 (93%)]	Loss: 2.322955
Train Epoch: 1 [56320/60000 (94%)]	Loss: 2.323627
Train Epoch: 1 [56960/60000 (95%)]	Loss: 2.323663
Train Epoch: 1 [57600/60000 (96%)]	Loss: 2.312716
Train Epoch: 1 [58240/60000 (97%)]	Loss: 2.293012
Train Epoch: 1 [58880/60000 (98%)]	Loss: 2.275046
Train Epoch: 1 [59520/60000 (99%)]	Loss: 2.297192
1e-05
